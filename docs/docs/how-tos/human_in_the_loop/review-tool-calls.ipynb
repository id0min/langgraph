{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "51466c8d-8ce4-4b3d-be4e-18fdbeda5f53",
   "metadata": {},
   "source": [
    "# How to Review Tool Calls\n",
    "\n",
    "Human-in-the-loop (HIL) interactions are crucial for [agentic systems](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/#human-in-the-loop). A common pattern is to add some human in the loop step after certain tool calls. These tool calls often lead to either a function call or saving of some information. Examples include:\n",
    "\n",
    "- A tool call to execute SQL, which will then be run by the tool\n",
    "- A tool call to generate a summary, which will then be saved to the State of the graph\n",
    "\n",
    "Note that using tool calls is common **whether actually calling tools or not**.\n",
    "\n",
    "There are typically a few different interactions you may want to do here:\n",
    "\n",
    "1. Approve the tool call and continue\n",
    "2. Modify the tool call manually and then continue\n",
    "3. Give natural language feedback, and then pass that back to the agent instead of continuing\n",
    "\n",
    "We can implement this in LangGraph using a [breakpoint](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/breakpoints/): breakpoints allow us to interrupt graph execution before a specific step. At this breakpoint, we can manually update the graph state taking one of the three options above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbd446a-808f-4394-be92-d45ab818953c",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First we need to install the packages required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af4ce0ba-7596-4e5f-8bf8-0b0bd6e62833",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph langchain_anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abe11f4-62ed-4dc4-8875-3db21e260d1d",
   "metadata": {},
   "source": [
    "Next, we need to set API keys for Anthropic (the LLM we will use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c903a1cf-2977-4e2d-ad7d-8b3946821d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"ANTHROPIC_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ed46a8-effe-4596-b0e1-a6a29ee16f5c",
   "metadata": {},
   "source": [
    "<div class=\"admonition tip\">\n",
    "    <p class=\"admonition-title\">Set up <a href=\"https://smith.langchain.com\">LangSmith</a> for LangGraph development</p>\n",
    "    <p style=\"padding-top: 5px;\">\n",
    "        Sign up for LangSmith to quickly spot issues and improve the performance of your LangGraph projects. LangSmith lets you use trace data to debug, test, and monitor your LLM apps built with LangGraph â€” read more about how to get started <a href=\"https://docs.smith.langchain.com\">here</a>. \n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035e567c-db5c-4085-ba4e-5b3814561c21",
   "metadata": {},
   "source": [
    "## Simple Usage\n",
    "\n",
    "Let's set up a very simple graph that facilitates this.\n",
    "First, we will have an LLM call that decides what action to take.\n",
    "Then we go to a human node. This node actually doesn't do anything - the idea is that we interrupt before this node and then apply any updates to the state.\n",
    "After that, we check the state and either route back to the LLM or to the correct tool.\n",
    "\n",
    "Let's see this in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85e452f8-f33a-4ead-bb4d-7386cdba8edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing_extensions import TypedDict, Literal\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import AIMessage\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "@tool\n",
    "def weather_search(city: str):\n",
    "    \"\"\"Search for the weather\"\"\"\n",
    "    print(\"----\")\n",
    "    print(f\"Searching for: {city}\")\n",
    "    print(\"----\")\n",
    "    return \"Sunny!\"\n",
    "\n",
    "\n",
    "model = ChatAnthropic(model_name=\"claude-3-5-sonnet-20240620\").bind_tools(\n",
    "    [weather_search]\n",
    ")\n",
    "\n",
    "\n",
    "class State(MessagesState):\n",
    "    \"\"\"Simple state.\"\"\"\n",
    "\n",
    "\n",
    "def call_llm(state):\n",
    "    return {\"messages\": [model.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "def human_review_node(state):\n",
    "    pass\n",
    "\n",
    "\n",
    "def run_tool(state):\n",
    "    new_messages = []\n",
    "    tools = {\"weather_search\": weather_search}\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    for tool_call in tool_calls:\n",
    "        tool = tools[tool_call[\"name\"]]\n",
    "        result = tool.invoke(tool_call[\"args\"])\n",
    "        new_messages.append(\n",
    "            {\n",
    "                \"role\": \"tool\",\n",
    "                \"name\": tool_call[\"name\"],\n",
    "                \"content\": result,\n",
    "                \"tool_call_id\": tool_call[\"id\"],\n",
    "            }\n",
    "        )\n",
    "    return {\"messages\": new_messages}\n",
    "\n",
    "\n",
    "def route_after_llm(state) -> Literal[END, \"human_review_node\"]:\n",
    "    if len(state[\"messages\"][-1].tool_calls) == 0:\n",
    "        return END\n",
    "    else:\n",
    "        return \"human_review_node\"\n",
    "\n",
    "\n",
    "def route_after_human(state) -> Literal[\"run_tool\", \"call_llm\"]:\n",
    "    if isinstance(state[\"messages\"][-1], AIMessage):\n",
    "        return \"run_tool\"\n",
    "    else:\n",
    "        return \"call_llm\"\n",
    "\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(call_llm)\n",
    "builder.add_node(run_tool)\n",
    "builder.add_node(human_review_node)\n",
    "builder.add_edge(START, \"call_llm\")\n",
    "builder.add_conditional_edges(\"call_llm\", route_after_llm)\n",
    "builder.add_conditional_edges(\"human_review_node\", route_after_human)\n",
    "builder.add_edge(\"run_tool\", \"call_llm\")\n",
    "\n",
    "import sqlite3\n",
    "conn = sqlite3.connect(\":memory:\")\n",
    "memory = SqliteSaver(conn)\n",
    "\n",
    "# Add\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d246d39f-4b36-459b-bd54-bf363753e590",
   "metadata": {},
   "source": [
    "## Example with no review\n",
    "\n",
    "Let's look at an example when no review is required (because no tools are called)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b3aa6fc-c7fb-4819-8d7f-ba6057cc4edf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "SQLite objects created in a thread can only be used in that same thread. The object was created in thread id 8799813888 and this is thread id 6264860672.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m thread \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigurable\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthread_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m\"\u001b[39m}}\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Run the graph until the first interruption\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workplace/permchain/libs/langgraph/langgraph/pregel/__init__.py:1600\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   1598\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1599\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1600\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1601\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1602\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1603\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1604\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1605\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1606\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1608\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1609\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1610\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[0;32m~/workplace/permchain/libs/langgraph/langgraph/pregel/__init__.py:1276\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustom\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m stream_modes:\n\u001b[1;32m   1273\u001b[0m     config[CONF][CONFIG_KEY_STREAM_WRITER] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m c: stream\u001b[38;5;241m.\u001b[39mput(\n\u001b[1;32m   1274\u001b[0m         ((), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustom\u001b[39m\u001b[38;5;124m\"\u001b[39m, c)\n\u001b[1;32m   1275\u001b[0m     )\n\u001b[0;32m-> 1276\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSyncPregelLoop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1277\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStreamProtocol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_modes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1281\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpointer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspecs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_channels_asis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# create runner\u001b[39;49;00m\n\u001b[1;32m   1289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mPregelRunner\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1290\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubmit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mput_writes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mput_writes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnode_finished\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[43mCONF\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONFIG_KEY_NODE_FINISHED\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# enable subgraph streaming\u001b[39;49;00m\n",
      "File \u001b[0;32m~/workplace/permchain/libs/langgraph/langgraph/pregel/loop.py:741\u001b[0m, in \u001b[0;36mSyncPregelLoop.__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    736\u001b[0m     exc_type: Optional[Type[\u001b[38;5;167;01mBaseException\u001b[39;00m]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    739\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mbool\u001b[39m]:\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;66;03m# unwind stack\u001b[39;00m\n\u001b[0;32m--> 741\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__exit__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexc_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/contextlib.py:586\u001b[0m, in \u001b[0;36mExitStack.__exit__\u001b[0;34m(self, *exc_details)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;66;03m# bare \"raise exc_details[1]\" replaces our carefully\u001b[39;00m\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;66;03m# set-up context\u001b[39;00m\n\u001b[1;32m    585\u001b[0m     fixed_ctx \u001b[38;5;241m=\u001b[39m exc_details[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39m__context__\n\u001b[0;32m--> 586\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_details[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[1;32m    588\u001b[0m     exc_details[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39m__context__ \u001b[38;5;241m=\u001b[39m fixed_ctx\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/contextlib.py:571\u001b[0m, in \u001b[0;36mExitStack.__exit__\u001b[0;34m(self, *exc_details)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m is_sync\n\u001b[1;32m    570\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcb\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mexc_details\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    572\u001b[0m         suppressed_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    573\u001b[0m         pending_raise \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/workplace/permchain/libs/langgraph/langgraph/pregel/executor.py:107\u001b[0m, in \u001b[0;36mBackgroundExecutor.__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 107\u001b[0m     \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mCancelledError:\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/workplace/permchain/libs/langgraph/langgraph/pregel/loop.py:666\u001b[0m, in \u001b[0;36mSyncPregelLoop._checkpointer_put_after_previous\u001b[0;34m(self, prev, config, checkpoint, metadata, new_versions)\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    665\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m prev \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 666\u001b[0m         \u001b[43mprev\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     cast(BaseCheckpointSaver, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpointer)\u001b[38;5;241m.\u001b[39mput(\n\u001b[1;32m    669\u001b[0m         config, checkpoint, metadata, new_versions\n\u001b[1;32m    670\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/workplace/permchain/libs/langgraph/langgraph/pregel/executor.py:70\u001b[0m, in \u001b[0;36mBackgroundExecutor.done\u001b[0;34m(self, task)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdone\u001b[39m(\u001b[38;5;28mself\u001b[39m, task: concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mFuture) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 70\u001b[0m         \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m GraphInterrupt:\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;66;03m# This exception is an interruption signal, not an error\u001b[39;00m\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;66;03m# so we don't want to re-raise it on exit\u001b[39;00m\n\u001b[1;32m     74\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mpop(task)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/workplace/permchain/libs/langgraph/langgraph/pregel/loop.py:668\u001b[0m, in \u001b[0;36mSyncPregelLoop._checkpointer_put_after_previous\u001b[0;34m(self, prev, config, checkpoint, metadata, new_versions)\u001b[0m\n\u001b[1;32m    666\u001b[0m         prev\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m--> 668\u001b[0m     \u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBaseCheckpointSaver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpointer\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mput\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_versions\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workplace/permchain/libs/checkpoint-sqlite/langgraph/checkpoint/sqlite/__init__.py:401\u001b[0m, in \u001b[0;36mSqliteSaver.put\u001b[0;34m(self, config, checkpoint, metadata, new_versions)\u001b[0m\n\u001b[1;32m    399\u001b[0m type_, serialized_checkpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserde\u001b[38;5;241m.\u001b[39mdumps_typed(checkpoint)\n\u001b[1;32m    400\u001b[0m serialized_metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjsonplus_serde\u001b[38;5;241m.\u001b[39mdumps(metadata)\n\u001b[0;32m--> 401\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcursor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcur\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mINSERT OR REPLACE INTO checkpoints (thread_id, checkpoint_ns, checkpoint_id, parent_checkpoint_id, type, checkpoint, metadata) VALUES (?, ?, ?, ?, ?, ?, ?)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigurable\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m    416\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthread_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: thread_id,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    419\u001b[0m     }\n\u001b[1;32m    420\u001b[0m }\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/workplace/permchain/libs/checkpoint-sqlite/langgraph/checkpoint/sqlite/__init__.py:169\u001b[0m, in \u001b[0;36mSqliteSaver.cursor\u001b[0;34m(self, transaction)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlock:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup()\n\u001b[0;32m--> 169\u001b[0m     cur \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcursor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    171\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m cur\n",
      "\u001b[0;31mProgrammingError\u001b[0m: SQLite objects created in a thread can only be used in that same thread. The object was created in thread id 8799813888 and this is thread id 6264860672."
     ]
    }
   ],
   "source": [
    "# Input\n",
    "initial_input = {\"messages\": [{\"role\": \"user\", \"content\": \"hi!\"}]}\n",
    "\n",
    "# Thread\n",
    "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Run the graph until the first interruption\n",
    "graph.invoke(initial_input, thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa4ae514-ac3d-4b75-b0c8-bb415d04e816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(graph.get_state_history(thread, filter={\"foo\": \"foo\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59dc607-e70d-497b-aac9-78c847c27042",
   "metadata": {},
   "source": [
    "If we check the state, we can see that it is finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "213323cc-0320-4313-ab11-19042e28b495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pending Executions!\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "print(\"Pending Executions!\")\n",
    "print(graph.get_state(thread).next)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1985f7-54f1-420f-a2b6-5e6154909966",
   "metadata": {},
   "source": [
    "## Example of approving tool\n",
    "\n",
    "Let's now look at what it looks like to approve a tool call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2561a38f-edb5-4b44-b2d7-6a7b70d2e6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content=\"what's the weather in sf?\", id='8bda37cc-4bd3-4a14-bca5-b992934e710b')]}\n",
      "{'messages': [HumanMessage(content=\"what's the weather in sf?\", id='8bda37cc-4bd3-4a14-bca5-b992934e710b'), AIMessage(content=[{'text': 'To get the weather information for San Francisco, I can use the weather_search function. Let me do that for you.', 'type': 'text'}, {'id': 'toolu_01MW3ETLpq4b8s6VaAMgDBZP', 'input': {'city': 'San Francisco'}, 'name': 'weather_search', 'type': 'tool_use'}], response_metadata={'id': 'msg_019FjC1prjVv8BuQX7DmF65F', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 360, 'output_tokens': 80}}, id='run-1b580410-173c-4fe0-a149-22e8f516b259-0', tool_calls=[{'name': 'weather_search', 'args': {'city': 'San Francisco'}, 'id': 'toolu_01MW3ETLpq4b8s6VaAMgDBZP', 'type': 'tool_call'}], usage_metadata={'input_tokens': 360, 'output_tokens': 80, 'total_tokens': 440})]}\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "initial_input = {\"messages\": [{\"role\": \"user\", \"content\": \"what's the weather in sf?\"}]}\n",
    "\n",
    "# Thread\n",
    "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Run the graph until the first interruption\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef6d51c-e2b6-4266-8de7-acf1a0b62a57",
   "metadata": {},
   "source": [
    "If we now check, we can see that it is waiting on human review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33d68f0f-d435-4dd1-8013-6a59186dc9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pending Executions!\n",
      "('human_review_node',)\n"
     ]
    }
   ],
   "source": [
    "print(\"Pending Executions!\")\n",
    "print(graph.get_state(thread).next)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c99fdd-4204-4c2d-b1af-02f38ab6ad57",
   "metadata": {},
   "source": [
    "To approve the tool call, we can just continue the thread with no edits. To do this, we just create a new run with no inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9a0d5d4-52ff-49e0-a6f4-41f9a0e844d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "Searching for: San Francisco\n",
      "----\n",
      "{'messages': [HumanMessage(content=\"what's the weather in sf?\", id='8bda37cc-4bd3-4a14-bca5-b992934e710b'), AIMessage(content=[{'text': 'To get the weather information for San Francisco, I can use the weather_search function. Let me do that for you.', 'type': 'text'}, {'id': 'toolu_01MW3ETLpq4b8s6VaAMgDBZP', 'input': {'city': 'San Francisco'}, 'name': 'weather_search', 'type': 'tool_use'}], response_metadata={'id': 'msg_019FjC1prjVv8BuQX7DmF65F', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 360, 'output_tokens': 80}}, id='run-1b580410-173c-4fe0-a149-22e8f516b259-0', tool_calls=[{'name': 'weather_search', 'args': {'city': 'San Francisco'}, 'id': 'toolu_01MW3ETLpq4b8s6VaAMgDBZP', 'type': 'tool_call'}], usage_metadata={'input_tokens': 360, 'output_tokens': 80, 'total_tokens': 440}), ToolMessage(content='Sunny!', name='weather_search', id='835b0fe3-8aa0-45d5-ac29-03bbe57cc767', tool_call_id='toolu_01MW3ETLpq4b8s6VaAMgDBZP')]}\n",
      "{'messages': [HumanMessage(content=\"what's the weather in sf?\", id='8bda37cc-4bd3-4a14-bca5-b992934e710b'), AIMessage(content=[{'text': 'To get the weather information for San Francisco, I can use the weather_search function. Let me do that for you.', 'type': 'text'}, {'id': 'toolu_01MW3ETLpq4b8s6VaAMgDBZP', 'input': {'city': 'San Francisco'}, 'name': 'weather_search', 'type': 'tool_use'}], response_metadata={'id': 'msg_019FjC1prjVv8BuQX7DmF65F', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 360, 'output_tokens': 80}}, id='run-1b580410-173c-4fe0-a149-22e8f516b259-0', tool_calls=[{'name': 'weather_search', 'args': {'city': 'San Francisco'}, 'id': 'toolu_01MW3ETLpq4b8s6VaAMgDBZP', 'type': 'tool_call'}], usage_metadata={'input_tokens': 360, 'output_tokens': 80, 'total_tokens': 440}), ToolMessage(content='Sunny!', name='weather_search', id='835b0fe3-8aa0-45d5-ac29-03bbe57cc767', tool_call_id='toolu_01MW3ETLpq4b8s6VaAMgDBZP'), AIMessage(content=\"Based on the search results, the weather in San Francisco is sunny! It's a beautiful day in the city. Is there anything else you'd like to know about the weather or any other information I can help you with?\", response_metadata={'id': 'msg_01UY2d6RCzvwagwMb1J5etek', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 453, 'output_tokens': 49}}, id='run-7137f52c-abe6-4dc1-b536-92dd1d9187b0-0', usage_metadata={'input_tokens': 453, 'output_tokens': 49, 'total_tokens': 502})]}\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d30c4a7-b480-4ede-b2b4-8ec11de95e30",
   "metadata": {},
   "source": [
    "## Edit Tool Call\n",
    "\n",
    "Let's now say we want to edit the tool call. E.g. change some of the parameters (or even the tool called!) but then execute that tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec77831c-e6b8-4903-9146-e098a4b2fda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content=\"what's the weather in sf?\", id='0c488edd-7b9c-4416-ba02-8a2d7e9f2597')]}\n",
      "{'messages': [HumanMessage(content=\"what's the weather in sf?\", id='0c488edd-7b9c-4416-ba02-8a2d7e9f2597'), AIMessage(content=[{'text': \"Certainly! I can help you check the weather in San Francisco. To get this information, I'll use the weather search tool. Let me fetch that for you.\", 'type': 'text'}, {'id': 'toolu_01CpbVmprQnjxpQzx8MzE1g8', 'input': {'city': 'San Francisco'}, 'name': 'weather_search', 'type': 'tool_use'}], response_metadata={'id': 'msg_01Mv7iqdtPgZEX2LiBBqWDuY', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 360, 'output_tokens': 88}}, id='run-52a09799-efb5-4fff-82c3-884e20119ad3-0', tool_calls=[{'name': 'weather_search', 'args': {'city': 'San Francisco'}, 'id': 'toolu_01CpbVmprQnjxpQzx8MzE1g8', 'type': 'tool_call'}], usage_metadata={'input_tokens': 360, 'output_tokens': 88, 'total_tokens': 448})]}\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "initial_input = {\"messages\": [{\"role\": \"user\", \"content\": \"what's the weather in sf?\"}]}\n",
    "\n",
    "# Thread\n",
    "thread = {\"configurable\": {\"thread_id\": \"5\"}}\n",
    "\n",
    "# Run the graph until the first interruption\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edcffbd7-829b-4d0c-88bf-cd531bc0e6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pending Executions!\n",
      "('human_review_node',)\n"
     ]
    }
   ],
   "source": [
    "print(\"Pending Executions!\")\n",
    "print(graph.get_state(thread).next)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87358aca-9b8f-48c7-98d4-3d755f6b0104",
   "metadata": {},
   "source": [
    "To do this, we first need to update the state. We can do this by passing a message in with the **same** id of the message we want to overwrite. This will have the effect of **replacing** that old message. Note that this is only possible because of the **reducer** we are using that replaces messages with the same ID - read more about that [here](https://langchain-ai.github.io/langgraph/concepts/low_level/#working-with-messages-in-graph-state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df4a9900-d953-4465-b8af-bd2858cb63ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current State:\n",
      "{'messages': [HumanMessage(content=\"what's the weather in sf?\", id='0c488edd-7b9c-4416-ba02-8a2d7e9f2597'), AIMessage(content=[{'text': \"Certainly! I can help you check the weather in San Francisco. To get this information, I'll use the weather search tool. Let me fetch that for you.\", 'type': 'text'}, {'id': 'toolu_01CpbVmprQnjxpQzx8MzE1g8', 'input': {'city': 'San Francisco'}, 'name': 'weather_search', 'type': 'tool_use'}], response_metadata={'id': 'msg_01Mv7iqdtPgZEX2LiBBqWDuY', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 360, 'output_tokens': 88}}, id='run-52a09799-efb5-4fff-82c3-884e20119ad3-0', tool_calls=[{'name': 'weather_search', 'args': {'city': 'San Francisco'}, 'id': 'toolu_01CpbVmprQnjxpQzx8MzE1g8', 'type': 'tool_call'}], usage_metadata={'input_tokens': 360, 'output_tokens': 88, 'total_tokens': 448})]}\n",
      "\n",
      "Current Tool Call ID:\n",
      "toolu_01CpbVmprQnjxpQzx8MzE1g8\n",
      "----\n",
      "Searching for: San Francisco, USA\n",
      "----\n",
      "{'messages': [HumanMessage(content=\"what's the weather in sf?\", id='0c488edd-7b9c-4416-ba02-8a2d7e9f2597'), AIMessage(content=[{'text': \"Certainly! I can help you check the weather in San Francisco. To get this information, I'll use the weather search tool. Let me fetch that for you.\", 'type': 'text'}, {'id': 'toolu_01CpbVmprQnjxpQzx8MzE1g8', 'input': {'city': 'San Francisco'}, 'name': 'weather_search', 'type': 'tool_use'}], id='run-52a09799-efb5-4fff-82c3-884e20119ad3-0', tool_calls=[{'name': 'weather_search', 'args': {'city': 'San Francisco, USA'}, 'id': 'toolu_01CpbVmprQnjxpQzx8MzE1g8', 'type': 'tool_call'}]), ToolMessage(content='Sunny!', name='weather_search', id='ff968b9f-9b87-4893-9f32-dfb88dbe0536', tool_call_id='toolu_01CpbVmprQnjxpQzx8MzE1g8')]}\n",
      "{'messages': [HumanMessage(content=\"what's the weather in sf?\", id='0c488edd-7b9c-4416-ba02-8a2d7e9f2597'), AIMessage(content=[{'text': \"Certainly! I can help you check the weather in San Francisco. To get this information, I'll use the weather search tool. Let me fetch that for you.\", 'type': 'text'}, {'id': 'toolu_01CpbVmprQnjxpQzx8MzE1g8', 'input': {'city': 'San Francisco'}, 'name': 'weather_search', 'type': 'tool_use'}], id='run-52a09799-efb5-4fff-82c3-884e20119ad3-0', tool_calls=[{'name': 'weather_search', 'args': {'city': 'San Francisco, USA'}, 'id': 'toolu_01CpbVmprQnjxpQzx8MzE1g8', 'type': 'tool_call'}]), ToolMessage(content='Sunny!', name='weather_search', id='ff968b9f-9b87-4893-9f32-dfb88dbe0536', tool_call_id='toolu_01CpbVmprQnjxpQzx8MzE1g8'), AIMessage(content=\"Great news! The weather in San Francisco is currently sunny. It's a beautiful day in the city by the bay. Is there anything else you'd like to know about the weather or any other information I can help you with?\", response_metadata={'id': 'msg_01PhwUeRWkSJB6kzHZS361XZ', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 464, 'output_tokens': 50}}, id='run-5aebcf37-626e-4675-b225-476bc99bdbb8-0', usage_metadata={'input_tokens': 464, 'output_tokens': 50, 'total_tokens': 514})]}\n"
     ]
    }
   ],
   "source": [
    "# To get the ID of the message we want to replace, we need to fetch the current state and find it there.\n",
    "state = graph.get_state(thread)\n",
    "print(\"Current State:\")\n",
    "print(state.values)\n",
    "print(\"\\nCurrent Tool Call ID:\")\n",
    "current_content = state.values[\"messages\"][-1].content\n",
    "current_id = state.values[\"messages\"][-1].id\n",
    "tool_call_id = state.values[\"messages\"][-1].tool_calls[0][\"id\"]\n",
    "print(tool_call_id)\n",
    "\n",
    "# We now need to construct a replacement tool call.\n",
    "# We will change the argument to be `San Francisco, USA`\n",
    "# Note that we could change any number of arguments or tool names - it just has to be a valid one\n",
    "new_message = {\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": current_content,\n",
    "    \"tool_calls\": [\n",
    "        {\n",
    "            \"id\": tool_call_id,\n",
    "            \"name\": \"weather_search\",\n",
    "            \"args\": {\"city\": \"San Francisco, USA\"},\n",
    "        }\n",
    "    ],\n",
    "    # This is important - this needs to be the same as the message you replacing!\n",
    "    # Otherwise, it will show up as a separate message\n",
    "    \"id\": current_id,\n",
    "}\n",
    "graph.update_state(\n",
    "    # This is the config which represents this thread\n",
    "    thread,\n",
    "    # This is the updated value we want to push\n",
    "    {\"messages\": [new_message]},\n",
    "    # We push this update acting as our human_review_node\n",
    "    as_node=\"human_review_node\",\n",
    ")\n",
    "\n",
    "# Let's now continue executing from here\n",
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14acc96-3d50-44b1-8616-b8d9131e46c4",
   "metadata": {},
   "source": [
    "## Give feedback to a tool call\n",
    "\n",
    "Sometimes, you may not want to execute a tool call, but you also may not want to ask the user to manually modify the tool call. In that case it may be better to get natural language feedback from the user. You can then insert these feedback as a mock **RESULT** of the tool call.\n",
    "\n",
    "There are multiple ways to do this:\n",
    "\n",
    "1. You could add a new message to the state (representing the \"result\" of a tool call)\n",
    "2. You could add TWO new messages to the state - one representing an \"error\" from the tool call, other HumanMessage representing the feedback\n",
    "\n",
    "Both are similar in that they involve adding messages to the state. The main difference lies in the logic AFTER the `human_node` and how it handles different types of messages.\n",
    "\n",
    "For this example we will just add a single tool call representing the feedback. Let's see this in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d57d5131-7912-4216-aa87-b7272507fa51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content=\"what's the weather in sf?\", id='601c4c75-f506-4d91-896d-5e382123de24')]}\n",
      "{'messages': [HumanMessage(content=\"what's the weather in sf?\", id='601c4c75-f506-4d91-896d-5e382123de24'), AIMessage(content=[{'text': \"Certainly! I can help you check the weather in San Francisco. To get the most accurate and up-to-date information, I'll use the weather search tool. Let me fetch that for you right away.\", 'type': 'text'}, {'id': 'toolu_014UTKh5uqfc885Fj4RRqGdg', 'input': {'city': 'San Francisco'}, 'name': 'weather_search', 'type': 'tool_use'}], response_metadata={'id': 'msg_013nHyPYxNXFSoXeS6q4oWua', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 360, 'output_tokens': 98}}, id='run-0537e15e-86a4-4c6f-8dfb-6e4c160812c4-0', tool_calls=[{'name': 'weather_search', 'args': {'city': 'San Francisco'}, 'id': 'toolu_014UTKh5uqfc885Fj4RRqGdg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 360, 'output_tokens': 98, 'total_tokens': 458})]}\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "initial_input = {\"messages\": [{\"role\": \"user\", \"content\": \"what's the weather in sf?\"}]}\n",
    "\n",
    "# Thread\n",
    "thread = {\"configurable\": {\"thread_id\": \"6\"}}\n",
    "\n",
    "# Run the graph until the first interruption\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e33ad664-0307-43c5-b85a-1e02eebceb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pending Executions!\n",
      "('human_review_node',)\n"
     ]
    }
   ],
   "source": [
    "print(\"Pending Executions!\")\n",
    "print(graph.get_state(thread).next)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483d9455-8625-4c6a-9b98-f731403b2ed3",
   "metadata": {},
   "source": [
    "To do this, we first need to update the state. We can do this by passing a message in with the same **tool call id** of the tool call we want to respond to. Note that this is a **different** ID from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f05f8b6-6128-4de5-8884-862fc93f1227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current State:\n",
      "{'messages': [HumanMessage(content=\"what's the weather in sf?\", id='601c4c75-f506-4d91-896d-5e382123de24'), AIMessage(content=[{'text': \"Certainly! I can help you check the weather in San Francisco. To get the most accurate and up-to-date information, I'll use the weather search tool. Let me fetch that for you right away.\", 'type': 'text'}, {'id': 'toolu_014UTKh5uqfc885Fj4RRqGdg', 'input': {'city': 'San Francisco'}, 'name': 'weather_search', 'type': 'tool_use'}], response_metadata={'id': 'msg_013nHyPYxNXFSoXeS6q4oWua', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 360, 'output_tokens': 98}}, id='run-0537e15e-86a4-4c6f-8dfb-6e4c160812c4-0', tool_calls=[{'name': 'weather_search', 'args': {'city': 'San Francisco'}, 'id': 'toolu_014UTKh5uqfc885Fj4RRqGdg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 360, 'output_tokens': 98, 'total_tokens': 458})]}\n",
      "\n",
      "Current Tool Call ID:\n",
      "toolu_014UTKh5uqfc885Fj4RRqGdg\n",
      "{'messages': [HumanMessage(content=\"what's the weather in sf?\", id='601c4c75-f506-4d91-896d-5e382123de24'), AIMessage(content=[{'text': \"Certainly! I can help you check the weather in San Francisco. To get the most accurate and up-to-date information, I'll use the weather search tool. Let me fetch that for you right away.\", 'type': 'text'}, {'id': 'toolu_014UTKh5uqfc885Fj4RRqGdg', 'input': {'city': 'San Francisco'}, 'name': 'weather_search', 'type': 'tool_use'}], response_metadata={'id': 'msg_013nHyPYxNXFSoXeS6q4oWua', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 360, 'output_tokens': 98}}, id='run-0537e15e-86a4-4c6f-8dfb-6e4c160812c4-0', tool_calls=[{'name': 'weather_search', 'args': {'city': 'San Francisco'}, 'id': 'toolu_014UTKh5uqfc885Fj4RRqGdg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 360, 'output_tokens': 98, 'total_tokens': 458}), ToolMessage(content='User requested changes: pass in the country as well', name='weather_search', id='e20ceddc-a0d3-469d-b31e-512f3042a07e', tool_call_id='toolu_014UTKh5uqfc885Fj4RRqGdg'), AIMessage(content=[{'text': \"I apologize for the oversight. It seems that the weather search function requires more specific information. Let's try again with a more detailed search, including the country. Since San Francisco is commonly associated with the one in California, USA, I'll use that. Here's the updated search:\", 'type': 'text'}, {'id': 'toolu_01AaipBbWDLjHnPcoApx8wRq', 'input': {'city': 'San Francisco, USA'}, 'name': 'weather_search', 'type': 'tool_use'}], response_metadata={'id': 'msg_018rErqC2cLe2VVhebdJf81e', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 480, 'output_tokens': 116}}, id='run-fcba65ed-400a-4783-9ecd-e22051682399-0', tool_calls=[{'name': 'weather_search', 'args': {'city': 'San Francisco, USA'}, 'id': 'toolu_01AaipBbWDLjHnPcoApx8wRq', 'type': 'tool_call'}], usage_metadata={'input_tokens': 480, 'output_tokens': 116, 'total_tokens': 596})]}\n"
     ]
    }
   ],
   "source": [
    "# To get the ID of the message we want to replace, we need to fetch the current state and find it there.\n",
    "state = graph.get_state(thread)\n",
    "print(\"Current State:\")\n",
    "print(state.values)\n",
    "print(\"\\nCurrent Tool Call ID:\")\n",
    "tool_call_id = state.values[\"messages\"][-1].tool_calls[0][\"id\"]\n",
    "print(tool_call_id)\n",
    "\n",
    "# We now need to construct a replacement tool call.\n",
    "# We will change the argument to be `San Francisco, USA`\n",
    "# Note that we could change any number of arguments or tool names - it just has to be a valid one\n",
    "new_message = {\n",
    "    \"role\": \"tool\",\n",
    "    # This is our natural language feedback\n",
    "    \"content\": \"User requested changes: pass in the country as well\",\n",
    "    \"name\": \"weather_search\",\n",
    "    \"tool_call_id\": tool_call_id,\n",
    "}\n",
    "graph.update_state(\n",
    "    # This is the config which represents this thread\n",
    "    thread,\n",
    "    # This is the updated value we want to push\n",
    "    {\"messages\": [new_message]},\n",
    "    # We push this update acting as our human_review_node\n",
    "    as_node=\"human_review_node\",\n",
    ")\n",
    "\n",
    "# Let's now continue executing from here\n",
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2e79ab-7cdb-42ce-b2ca-2932f8782c90",
   "metadata": {},
   "source": [
    "We can see that we now get to another breakpoint - because it went back to the model and got an entirely new prediction of what to call. Let's now approve this one and continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a30d40ad-611d-4ec3-84be-869ea05acb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pending Executions!\n",
      "('human_review_node',)\n",
      "----\n",
      "Searching for: San Francisco, USA\n",
      "----\n",
      "{'messages': [HumanMessage(content=\"what's the weather in sf?\", id='601c4c75-f506-4d91-896d-5e382123de24'), AIMessage(content=[{'text': \"Certainly! I can help you check the weather in San Francisco. To get the most accurate and up-to-date information, I'll use the weather search tool. Let me fetch that for you right away.\", 'type': 'text'}, {'id': 'toolu_014UTKh5uqfc885Fj4RRqGdg', 'input': {'city': 'San Francisco'}, 'name': 'weather_search', 'type': 'tool_use'}], response_metadata={'id': 'msg_013nHyPYxNXFSoXeS6q4oWua', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 360, 'output_tokens': 98}}, id='run-0537e15e-86a4-4c6f-8dfb-6e4c160812c4-0', tool_calls=[{'name': 'weather_search', 'args': {'city': 'San Francisco'}, 'id': 'toolu_014UTKh5uqfc885Fj4RRqGdg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 360, 'output_tokens': 98, 'total_tokens': 458}), ToolMessage(content='User requested changes: pass in the country as well', name='weather_search', id='e20ceddc-a0d3-469d-b31e-512f3042a07e', tool_call_id='toolu_014UTKh5uqfc885Fj4RRqGdg'), AIMessage(content=[{'text': \"I apologize for the oversight. It seems that the weather search function requires more specific information. Let's try again with a more detailed search, including the country. Since San Francisco is commonly associated with the one in California, USA, I'll use that. Here's the updated search:\", 'type': 'text'}, {'id': 'toolu_01AaipBbWDLjHnPcoApx8wRq', 'input': {'city': 'San Francisco, USA'}, 'name': 'weather_search', 'type': 'tool_use'}], response_metadata={'id': 'msg_018rErqC2cLe2VVhebdJf81e', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 480, 'output_tokens': 116}}, id='run-fcba65ed-400a-4783-9ecd-e22051682399-0', tool_calls=[{'name': 'weather_search', 'args': {'city': 'San Francisco, USA'}, 'id': 'toolu_01AaipBbWDLjHnPcoApx8wRq', 'type': 'tool_call'}], usage_metadata={'input_tokens': 480, 'output_tokens': 116, 'total_tokens': 596}), ToolMessage(content='Sunny!', name='weather_search', id='3f3ee262-70f5-422c-8e3f-6a9af758514d', tool_call_id='toolu_01AaipBbWDLjHnPcoApx8wRq')]}\n",
      "{'messages': [HumanMessage(content=\"what's the weather in sf?\", id='601c4c75-f506-4d91-896d-5e382123de24'), AIMessage(content=[{'text': \"Certainly! I can help you check the weather in San Francisco. To get the most accurate and up-to-date information, I'll use the weather search tool. Let me fetch that for you right away.\", 'type': 'text'}, {'id': 'toolu_014UTKh5uqfc885Fj4RRqGdg', 'input': {'city': 'San Francisco'}, 'name': 'weather_search', 'type': 'tool_use'}], response_metadata={'id': 'msg_013nHyPYxNXFSoXeS6q4oWua', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 360, 'output_tokens': 98}}, id='run-0537e15e-86a4-4c6f-8dfb-6e4c160812c4-0', tool_calls=[{'name': 'weather_search', 'args': {'city': 'San Francisco'}, 'id': 'toolu_014UTKh5uqfc885Fj4RRqGdg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 360, 'output_tokens': 98, 'total_tokens': 458}), ToolMessage(content='User requested changes: pass in the country as well', name='weather_search', id='e20ceddc-a0d3-469d-b31e-512f3042a07e', tool_call_id='toolu_014UTKh5uqfc885Fj4RRqGdg'), AIMessage(content=[{'text': \"I apologize for the oversight. It seems that the weather search function requires more specific information. Let's try again with a more detailed search, including the country. Since San Francisco is commonly associated with the one in California, USA, I'll use that. Here's the updated search:\", 'type': 'text'}, {'id': 'toolu_01AaipBbWDLjHnPcoApx8wRq', 'input': {'city': 'San Francisco, USA'}, 'name': 'weather_search', 'type': 'tool_use'}], response_metadata={'id': 'msg_018rErqC2cLe2VVhebdJf81e', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 480, 'output_tokens': 116}}, id='run-fcba65ed-400a-4783-9ecd-e22051682399-0', tool_calls=[{'name': 'weather_search', 'args': {'city': 'San Francisco, USA'}, 'id': 'toolu_01AaipBbWDLjHnPcoApx8wRq', 'type': 'tool_call'}], usage_metadata={'input_tokens': 480, 'output_tokens': 116, 'total_tokens': 596}), ToolMessage(content='Sunny!', name='weather_search', id='3f3ee262-70f5-422c-8e3f-6a9af758514d', tool_call_id='toolu_01AaipBbWDLjHnPcoApx8wRq'), AIMessage(content=\"Great news! The weather in San Francisco, USA is currently sunny. \\n\\nHere's a summary of the weather information:\\n- Location: San Francisco, USA\\n- Current conditions: Sunny\\n\\nIt's a beautiful day in San Francisco! The sunny weather is perfect for outdoor activities or simply enjoying the city. Remember to wear sunscreen and stay hydrated if you plan to spend time outside. \\n\\nIs there anything else you'd like to know about the weather in San Francisco or any other location?\", response_metadata={'id': 'msg_017Pnjyte2ZXAREgUvEqbUVt', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 609, 'output_tokens': 107}}, id='run-30c0d0ef-09a3-40ad-b410-80019b284983-0', usage_metadata={'input_tokens': 609, 'output_tokens': 107, 'total_tokens': 716})]}\n"
     ]
    }
   ],
   "source": [
    "print(\"Pending Executions!\")\n",
    "print(graph.get_state(thread).next)\n",
    "\n",
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    print(event)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
