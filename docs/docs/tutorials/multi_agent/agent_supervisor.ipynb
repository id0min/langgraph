{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0d30b6f7-3bec-4d9f-af50-43dfdc81ae6c",
      "metadata": {
        "id": "0d30b6f7-3bec-4d9f-af50-43dfdc81ae6c"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -U langgraph langchain_community langchain_google_genai langchain_experimental"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30c2f3de-c730-4aec-85a6-af2c2f058803",
      "metadata": {
        "id": "30c2f3de-c730-4aec-85a6-af2c2f058803"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "\n",
        "def _set_if_undefined(var: str):\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"Please provide your {var}\")\n",
        "\n",
        "\n",
        "_set_if_undefined(\"GOOGLE_API_KEY\")\n",
        "_set_if_undefined(\"TAVILY_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f04c6778-403b-4b49-9b93-678e910d5cec",
      "metadata": {
        "id": "f04c6778-403b-4b49-9b93-678e910d5cec"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_core.tools import tool\n",
        "from langchain_experimental.utilities import PythonREPL\n",
        "\n",
        "tavily_tool = TavilySearchResults(max_results=5)\n",
        "\n",
        "# This executes code locally, which can be unsafe\n",
        "repl = PythonREPL()\n",
        "\n",
        "\n",
        "@tool\n",
        "def python_repl_tool(\n",
        "    code: Annotated[str, \"The python code to execute to generate your chart.\"],\n",
        "):\n",
        "    \"\"\"Use this to execute python code and do math. If you want to see the output of a value,\n",
        "    you should print it out with `print(...)`. This is visible to the user.\"\"\"\n",
        "    try:\n",
        "        result = repl.run(code)\n",
        "    except BaseException as e:\n",
        "        return f\"Failed to execute. Error: {repr(e)}\"\n",
        "    result_str = f\"Successfully executed:\\n```python\\n{code}\\n```\\nStdout: {result}\"\n",
        "    return result_str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "df2bd80b-c477-4d74-8faa-1c0548622239",
      "metadata": {
        "id": "df2bd80b-c477-4d74-8faa-1c0548622239"
      },
      "outputs": [],
      "source": [
        "from typing import Literal\n",
        "from pydantic import BaseModel\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langgraph.graph import MessagesState, END\n",
        "from langgraph.types import Command\n",
        "\n",
        "\n",
        "members = [\"researcher\", \"coder\"]\n",
        "# Our team supervisor is an LLM node. It just picks the next agent to process\n",
        "# and decides when the work is completed\n",
        "options = members + [\"FINISH\"]\n",
        "\n",
        "system_prompt = (\n",
        "    \"You are a supervisor tasked with managing a conversation between the\"\n",
        "    f\" following workers: {members}. Given the following user request,\"\n",
        "    \" respond with the worker to act next. Each worker will perform a\"\n",
        "    \" task and respond with their results and status. When finished,\"\n",
        "    \" respond with FINISH.\"\n",
        ")\n",
        "\n",
        "\n",
        "class Router(BaseModel):\n",
        "    \"\"\"Worker to route to next. If no workers needed, route to FINISH.\"\"\"\n",
        "\n",
        "    next: Literal[\"researcher\", \"coder\", \"FINISH\"]\n",
        "\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
        "\n",
        "class State(MessagesState):\n",
        "    next: str\n",
        "\n",
        "\n",
        "def supervisor_node(state: State) -> Command[Literal[\"researcher\", \"coder\", \"__end__\"]]:\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "    ] + state[\"messages\"]\n",
        "    response = llm.with_structured_output(Router).invoke(messages)\n",
        "    goto = response.next\n",
        "    if goto == \"FINISH\":\n",
        "        goto = END\n",
        "\n",
        "    return Command(goto=goto, update={\"next\": goto})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6a430af7-8fce-4e66-ba9e-d940c1bc48e8",
      "metadata": {
        "id": "6a430af7-8fce-4e66-ba9e-d940c1bc48e8"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "\n",
        "research_agent = create_react_agent(\n",
        "    llm, tools=[tavily_tool], prompt=\"You are a researcher. DO NOT do any math.\"\n",
        ")\n",
        "\n",
        "\n",
        "def research_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
        "    result = research_agent.invoke(state)\n",
        "    return Command(\n",
        "        update={\n",
        "            \"messages\": [\n",
        "                HumanMessage(content=result[\"messages\"][-1].content, name=\"researcher\")\n",
        "            ]\n",
        "        },\n",
        "        goto=\"supervisor\",\n",
        "    )\n",
        "\n",
        "\n",
        "# NOTE: THIS PERFORMS ARBITRARY CODE EXECUTION, WHICH CAN BE UNSAFE WHEN NOT SANDBOXED\n",
        "code_agent = create_react_agent(llm, tools=[python_repl_tool])\n",
        "\n",
        "\n",
        "def code_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
        "    result = code_agent.invoke(state)\n",
        "    return Command(\n",
        "        update={\n",
        "            \"messages\": [\n",
        "                HumanMessage(content=result[\"messages\"][-1].content, name=\"coder\")\n",
        "            ]\n",
        "        },\n",
        "        goto=\"supervisor\",\n",
        "    )\n",
        "\n",
        "\n",
        "builder = StateGraph(State)\n",
        "builder.add_edge(START, \"supervisor\")\n",
        "builder.add_node(\"supervisor\", supervisor_node)\n",
        "builder.add_node(\"researcher\", research_node)\n",
        "builder.add_node(\"coder\", code_node)\n",
        "graph = builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0175fe14-5854-4197-b7e8-559335d0f81b",
      "metadata": {
        "id": "0175fe14-5854-4197-b7e8-559335d0f81b"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Image\n",
        "\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56ba78e9-d9c1-457c-a073-d606d5d3e013",
      "metadata": {
        "id": "56ba78e9-d9c1-457c-a073-d606d5d3e013"
      },
      "outputs": [],
      "source": [
        "for s in graph.stream(\n",
        "    {\"messages\": [(\"user\", \"What's the square root of 42?\")]}, subgraphs=True\n",
        "):\n",
        "    print(s)\n",
        "    print(\"----\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45a92dfd-0e11-47f5-aad4-b68d24990e34",
      "metadata": {
        "id": "45a92dfd-0e11-47f5-aad4-b68d24990e34"
      },
      "outputs": [],
      "source": [
        "for s in graph.stream(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            (\n",
        "                \"user\",\n",
        "                \"Find the latest GDP of New York and California, then calculate the average\",\n",
        "            )\n",
        "        ]\n",
        "    },\n",
        "    subgraphs=True,\n",
        "):\n",
        "    print(s)\n",
        "    print(\"----\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "wz8Q9AOS7E0o",
      "metadata": {
        "id": "wz8Q9AOS7E0o"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}